#!/bin/sh
# ==================================
# DAJIN - Genotyping software using Nanopore long-read sequencer for genome-edited samples
# Version: 2.0.2
# License: MIT
# Written by Akihiro Kuno
# <https://github.com/akikuno/DAJIN2>.
# ==================================
cat <<'EMBED' >.DAJIN_temp/document/README_JP.md

<p align="center">
<img src="https://github.com/akikuno/DAJIN/blob/master/misc/images/DAJIN-logo.png" width="90%">
</p>

[![MIT License](http://img.shields.io/badge/license-MIT-blue.svg?style=flat)](LICENSE)

## 特徴

- **移植性**：Windows10 (WSL), Linux, macOS
- **低依存性**：minimap2とsamtoolsのみ必要とします
- **高速**： DAJINの100倍高速です

## セットアップ

### 動作環境

LinuxまたはWindows 10 ([WSL](https://docs.microsoft.com/ja-jp/windows/wsl/install-win10))で動作確認をしています.  
検証済みの環境は[こちら](https://github.com/akikuno/DAJIN/blob/master/docs/TESTED_SYSTEMS.md)です.  

### `conda`をインストールします


wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
chmod +x Miniconda3-latest-Linux-x86_64.sh
./Miniconda3-latest-Linux-x86_64.sh

condaおよびインストールについての詳細は[こちら](https://docs.conda.io/projects/conda/en/latest/)にございます.  


### DAJINをダウンロードします

git clone https://github.com/akikuno/DAJIN.git

または下記URLでZIPファイルをダウンロードしてください.  

https://github.com/akikuno/DAJIN/archive/master.zip

### DAJINをダウンロードします


## 利用方法

### 入力ファイルの用意

以下のような入力ファイルを作製します.  

design=DAJIN/example/design.txt
input_dir=DAJIN/example/demultiplex
control=barcode01
genome=mm10
grna=CCTGTCCAGAGTGGGAGATAGCC,CCACTGCTAGCTGTGGGTAACCC
output_dir=DAJIN_cables2
threads=10
filter=on

各項目の情報は以下のとおりです. 各項目は順不同です.  

- **desing**: 考えられる遺伝型の配列を記載したFASTA形式のテキストファイルです.  ">wt"と">target"の2つは含まれている必要があります. 
- **input_dir**: demultiplex済みのFASTA/FASTQファイルを含むディレクトリです. 
- **control**: 野生型コントロールのバーコード番号です. 
- **genome**: `mm10`, `hg38`等の参照ゲノムです. 
- **grna**: PAMを含むgRNA配列です. 2つ以上の配列はコンマ（,）で区切ります. 
- **output_dir（オプショナル）**: 結果を保存するディレクトリの名前です. デフォルトは`DAJIN_results`です. 
- **threads（オプショナル）**: DAJINに使用するCPUスレッド数です. デフォルトでは`3分の2`を使用します. 
- **filter（オプショナル**: on/off）: マイナーアレル（3%以下）を解析から除きます. デフォルトは"on"です. 


### DAJINの実行

./DAJIN/DAJIN.sh -f [入力ファイルのPATH]

下記のコマンドで例を実行します.

./DAJIN/DAJIN.sh -i DAJIN/example/design.txt

### 結果のレポートについて

DAJINは2つのファイル（`Details.csv`, `Details.pdf`）と2つのフォルダ（`BAM`, `Consensus`）を出力します. 

#### Details.csv

`Details.csv` はアレル情報を記載しています.

| Sample    |  Allele ID |  % of reads |  Allele type  |  Indel |  Large indel |  Design |
|-----------|------------|-------------|---------------|--------|--------------|---------|
| barcode01 | 1          | 100         | wt            | -      | -            | -       |
| barcode02 | 1          | 11.8        | abnormal      | +      | +            | -       |
| barcode02 | 2          | 88.2        | target        | -      | -            | +       |
| barcode03 | 1          | 9.9         | abnormal      | +      | +            | -       |
| barcode03 | 2          | 38.5        | abnormal      | +      | +            | -       |
| barcode03 | 3          | 51.6        | flox_deletion | -      | -            | -       |

#### Details.pdf

`Details.pdf`は上記CSVを可視化した以下のような図です.  

<img src="https://github.com/akikuno/DAJIN/blob/master/misc/images/Details.png" width="75%">  

barcode01は野生型コントロールです. barcode02とbarcode03はfloxノックインのゲノム編集を施したファウンダーマウスの結果です.  
barcode02のほぼ全てのアレルがintact target （flox以外の異常な変異の入っていないアレル）であることから、このマウスは目的のfloxアレルをホモでもつマウスの候補と考えられます.  

#### Consensus

`Conseusus` フォルダーには各アレルのコンセンサス配列が保存されています.  
ファイル形式はFASTAおよびHTMLです.  

HTMLでは色付けされた変異情報が表示されます.  

<a href="https://htmlpreview.github.io/?https://github.com/akikuno/DAJIN/blob/master/misc/images/tyr_c140cg.html" target= _blank rel= noopener> こちらは点変異のコンセンサス配列です. </a>

#### BAM

`BAM` フォルダーには解析したサンプルの全アレルおよび各アレルごとのBAMファイルが保存されています.  
この`BAM`ファイルは[IGV](http://software.broadinstitute.org/software/igv/)で可視化できます.  

EMBED
cat <<'EMBED' >.DAJIN_temp/document/dependencies.md
# Dependencies

+ samtools (1.10)
+ minimap2 (2.17-r941)
+ Python (3.7.6)
  + numpy (1.18.5)
  + pandas (1.0.5)
  + scikit-learn (0.23.1)
  + plotnine (0.7.0)

> The number in the parenthesis represents the tested software version.
EMBED
cat <<'EMBED' >.DAJIN_temp/document/tested_systems.md
# Tested system information

We have tested DAJIN2 works in the following systems:

## Linux

---
| OS     | Ubuntu 18.04.3 LTS x86_64            |
| ------ | ------------------------------------ |
| Kernel | 5.0.0-29-generic                     |
| Shell  | bash 4.4.20                          |
| CPU    | Intel Xeon Gold 5220 (72) @ 3.900GHz |
| GPU    | NVIDIA GeForce RTX 2080 Ti x4        |
| Memory | 192 GB                               |
---
| OS     | Linux Mint 20 x86_64            |
| ------ | ------------------------------- |
| Kernel | 5.4.0-42-generic                |
| Shell  | bash 5.0.17                     |
| CPU    | AMD Ryzen 7 2700X (16) @ 3.700G |
| GPU    | NVIDIA GeForce GTX 1080 Ti      |
| Memory | 64 GB                           |

## macOS

## Windows 10 (WSL2)

---
| OS     | Ubuntu 18.04.5 LTS on Windows 10 x86_64 |
| ------ | --------------------------------------- |
| Kernel | 4.19.104-microsoft-standard             |
| Shell  | bash 4.4.20                             |
| CPU    | Intel Xeon E3-1535M v6 (8) @ 3.095GHz   |
| Memory | 64 GB                                   |
---
EMBED
cat <<'EMBED' >.DAJIN_temp/document/troubleshootings.md
# Troubleshootings

## line feed

DAJIN: 7: set: Illegal option -

This error may be caused by `CRLF`.

Please open `DAJIN` by your text editor (e.g. Visual Studio Code) and change the line feed from `CRLF` to `LF`.  

## samtools

EMBED
cat <<'EMBED' >.DAJIN_temp/document/usage.md
Usage:

  DAJIN [options] -a <alleles.fasta> -c <control.fastq> -s <sample.fastq>

Example:

  DAJIN \
    -a example/alleles.fa \
    -c example/fastq/barcode01.fq.gz \
    -s example/fastq/barcode02.fq.gz \
    -g mm10 \
    -o DAJIN_example \
    -t 4

Mandatory arguments:

  -a|--alleles <string>
    Name of a multi-fasta file describing DNA sequence of each alleles in specific regions of interest.

  -c|--control <string>
    Name of a fastq file from a control sample.
    Acceptable formats include gzipped FASTQ and FASTQ.

  -s|--sample <string>
    Name of a fastq file from an experimental sample.
    Acceptable formats include gzipped FASTQ and FASTQ.

Optional arguments (defaults in parentheses):

  -g|--genome <string>
    Name of UCSC genome releases.
    The available genomes are listed at https://genome.ucsc.edu/FAQ/FAQreleases.html#release1

  -t|--threads <integer>
    Number of threads to use (1)

  -o|--output <string>
    Output directory (DAJIN_results)

See the further information: <https://github.com/akikuno/DAJIN2>

EMBED
cat <<'EMBED' >.DAJIN_temp/document/version.md
DAJIN - Genotyping software using Nanopore long-read sequencer for genome-edited samples
Version: 2.0.2
License: MIT
Written by Akihiro Kuno
<https://github.com/akikuno/DAJIN2>.
EMBED
cat <<'EMBED' >.DAJIN_temp/util/consensus.html
<!DOCTYPE html>
<html>

<head>
  <style>
    p {
      font-family: "Courier New", Courier, monospace;
      color: #333333;
      width: 75%;
      letter-spacing: 1px;
      word-wrap: break-word;
    }

    .Ins {
      color: white;
      background-color: #F06060;
      font-weight: bold;
      /* padding: 2px; */
      background-clip: padding-box;
    }

    .Del {
      color: white;
      background-color: #3970B5;
      font-weight: bold;
      /* padding: 2px; */
      background-clip: padding-box;
    }

    .Sub {
      color: white;
      background-color: #3CB371;
      /* #03af7a */
      font-weight: bold;
      /* padding: 2px; */
      background-clip: padding-box;
    }

    .Inv {
      font-weight: bold;
      text-decoration: underline;
    }
  </style>
</head>

<body>
  <p>
    <!-- insert here -->
  </p>
  <hr>
  <p>
    <span class="Ins">Insertion</span> <span class="Del">Deletion</span> <span class="Sub">Substitution</span> <span
      class="Inv">Inversion</span>
  </p>
</body>

</html>
EMBED
cat <<'EMBED' >.DAJIN_temp/util/consensus_head.html
<!DOCTYPE html>
<html>

<head>
  <style>
    p {
      font-family: "Courier New", Courier, monospace;
      color: #333333;
      width: 75%;
      letter-spacing: 1px;
      word-wrap: break-word;
    }

    .Ins {
      color: white;
      background-color: #F06060;
      font-weight: bold;
      /* padding: 2px; */
      background-clip: padding-box;
    }

    .Del {
      color: white;
      background-color: #3970B5;
      font-weight: bold;
      /* padding: 2px; */
      background-clip: padding-box;
    }

    .Sub {
      color: white;
      background-color: #3CB371;
      /* #03af7a */
      font-weight: bold;
      /* padding: 2px; */
      background-clip: padding-box;
    }

    .Inv {
      font-weight: bold;
      text-decoration: underline;
    }
  </style>
</head>

<body>
  <p>
EMBED
cat <<'EMBED' >.DAJIN_temp/util/consensus_tail.html
</p>
<hr>
<p>
  <span class="Ins">Insertion</span> <span class="Del">Deletion</span> <span class="Sub">Substitution</span> <span
    class="Inv">Inversion</span>
</p>
</body>

</html>
EMBED
cat <<'EMBED' >.DAJIN_temp/util/mut_colors.csv
#B2DF8A,#FB9A99,#FDBF6F,#CAB2D6,#FFFF99
EMBED
cat <<'EMBED' >.DAJIN_temp/util/norm_colors.csv
#33A02C,#E31A1C,#FF7F00,#6A3D9A,#B15928
EMBED
cat <<'EMBED' >.DAJIN_temp/library/03-preprocess/maskByXXX.R
#!/usr/bin/env Rscript

###############################################################################
# Controlにも存在するDeletionをマスクする
###############################################################################

args <- commandArgs(trailingOnly = TRUE)

if (length(args) > 0) {
  sample <- read.table(args[1], sep = ",", header = FALSE, row.names = 1)
  control <- read.table(args[2], sep = ",", header = FALSE, row.names = 1)
} else {
  sample <- read.table("tmp_s.csv", sep = ",", header = FALSE, row.names = 1)
  control <- read.table("tmp_c.csv", sep = ",", header = FALSE, row.names = 1)
}

fn_prop <- function(x) prop.table(table(x))
list_sample <- lapply(sample, fn_prop)
list_control <- lapply(control, fn_prop)
idx = 829 #???????????????????????????????
idx = 1377 #???????????????????????????????
sample[[idx]]

# fn_max <- function(idx) {
#   tmp <- list_control[[idx]]
#   max(tmp[names(tmp) != "M"])
# }

# for (i in seq_along(list_control)) {
#   tmp_max <- fn_max(i)
# }
# tmp_max <- lapply(seq_along(list_control), fn_max)
# tmp_max <- unlist(tmp_max)
# summary(tmp_max)
# sum(tmp_max > 0.1)
# png("tmp.png")
# plot(tmp_max)
# dev.off()

# fn_match <- function(idx) {
#   tmp <- list_control[[idx]]
#   tmp[names(tmp) == "M"]
# }

# fn_sub <- function(idx) {
#   tmp <- list_control[[idx]]
#   tmp[names(tmp) == "S"]
# }
fn_del <- function(idx, list) {
  tmp <- list[[idx]]
  tmp[names(tmp) == "D"]
}
# fn_ins <- function(idx) {
#   tmp <- list_control[[idx]]
#   max(tmp[grepl("[0-9]",names(tmp))],0)
# }
# tmp_match <- unlist(lapply(seq_along(list_control), fn_match))
# tmp_sub <- unlist(lapply(seq_along(list_control), fn_sub))
# tmp_del <- unlist(lapply(seq_along(list_control), fn_del))
# tmp_ins <- unlist(lapply(seq_along(list_control), fn_ins))
# summary(tmp_sub)
# summary(tmp_del)
# summary(tmp_ins)
# png("tmp.png")
# par(mfrow=c(2,2))
# plot(tmp_match, ylim=c(0,1))
# plot(tmp_sub, ylim=c(0,1))
# plot(tmp_del, ylim=c(0,1))
# plot(tmp_ins, ylim=c(0,1))
# dev.off()


tmp_del_control <- unlist(lapply(seq_along(list_control), function(idx) fn_del(idx, list_control)))
tmp_del_sample <- unlist(lapply(seq_along(list_sample), function(idx) fn_del(idx, list_sample)))
which.max(tmp_del)
png("tmp.png")
par(mfrow=c(3,2))
plot(tmp_del_control, ylim=c(0,1), main="cont")
plot(tmp_del_sample, ylim=c(0,1), main="samp")
plot(tmp_del_control[(2146-50):(2146+50)], ylim=c(0,1), main="cont")
plot(tmp_del_sample[(2146-50):(2146+50)], ylim=c(0,1), main="samp")
plot(tmp_del_control[(829-50):(829-30)], ylim=c(0,1), main="cont")
plot(tmp_del_sample[(829-50):(829-30)], ylim=c(0,1), main="samp")
dev.off()

cossim <- function(v1, v2) {
  sum(v1 * v2)/sqrt(sum(v1^2) * sum(v2^2))
}
tmp <- cossim(tmp_del_control, tmp_del_sample)

cossim(tmp_del_control, tmp_del_control)

# sum(tmp_match < 0.8)
# sum((tmp_max > 0.1) | (tmp_match < 0.8))
# summary(tmp_match[(tmp_max > 0.1) | (tmp_match < 0.8)])
# which((tmp_max > 0.1) | (tmp_match < 0.8))

# fn_error_rate <- function(idx, list_sample, list_control) {
#   df_s <- as.data.frame(list_sample[[idx]])
#   df_c <- as.data.frame(list_control[[idx]])
#   df_sc <- merge(x = df_s, y = df_c, by = "x", all = TRUE)
#   df_sc[is.na(df_sc)] <- (1/10)^10

#   tmp <- 1 / (df_sc$Freq.x)
#   v_sub <- 1 - (df_sc$Freq.y * tmp)
#   v_sub[v_sub > 0.9] <- 1
#   v_sub[v_sub < 0] <- 0
#   names(v_sub) <- df_sc$x
#   v_sub <- v_sub[!is.infinite(v_sub)]
#   df_sub <- data.frame(x = names(v_sub), sc_ratio = v_sub)

#   df_merge <- merge(x = df_s$x, y = df_sub, by = "x")
#   return(df_merge)
# }

# list_error <- lapply(seq_along(list_sample),
#   function(idx) fn_error_rate(idx, list_sample, list_control))

# #? idx = 3
# fn_correction <- function(idx, sample, list_error){

#   df_x <- data.frame(x = sample[[idx]], id = rownames(sample))
#   df_merge <- merge(
#     x = df_x,
#     y = list_error[[idx]],
#     by = "x",
#     all.x = TRUE)
#   #? sum(df_merge$x == "D")
#   df_tmp <- unique(df_merge[,-2])
#   df_tmp <- df_tmp[df_tmp$sc_ratio != 1, ]

#   for (i in seq_along(df_tmp$x)) {
#     sc_ratio <- df_tmp[i, ]$sc_ratio
#     x <- df_tmp[i, ]$x
#     if ( sc_ratio == 0) {
#       df_merge$x[df_merge$x == x] <- "M"
#     } else {
#       df_merge$x[df_merge$x == x] <- sample(
#         c("M", x),
#         size = sum(df_merge$x == x),
#         replace = TRUE,
#         prob = c(sc_ratio, 1 - sc_ratio)
#         )
#     }
#   }
#   return(df_merge$x)
# }


# list_corrected <-
#   lapply(seq_along(sample),
#     function(idx) fn_correction(idx, sample, list_error))

# df_corrected <- as.data.frame(do.call(cbind, list_corrected))
# rownames(df_corrected) <- rownames(sample)

write.table(df_corrected,
  file = "",
  sep = ",", col.names = FALSE, row.names = TRUE, quote = FALSE
)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/03-preprocess/maskByPhred.R
#!/usr/bin/env Rscript

df <- read.table(file("stdin"), sep = ",", header = FALSE, row.names = 1)
# df <- read.table("tmp_maskMS.csv", sep = ",", header = FALSE, row.names = 1)

# vect <- df$V830
replacen <- function(vect) {
  
  v_table <- table(vect)
  v_omitn <- v_table[!grepl("N|n", names(v_table))]
  n_numbers <- sum(grepl("N|n", vect))

  if (length(v_omitn) == 0) {
    n_replace <- "M"
  } else {
    n_replace <- sample(
      names(v_omitn),
      size = n_numbers,
      replace = TRUE,
      prob = prop.table(v_omitn)
      )
  }

  vect[grepl("N|n", vect)] <- n_replace

  return(vect)
}

df_replacen <- apply(df, 2, replacen)

# ? （ほかの部位のほうが異常にDが集積しているという判定がされるため, ）
# ? アルビノ点変異部位には効果がありませんでした.
# ?  一旦コメントアウトします（2021-08-06）
# # replace D
# # Dの頻度が”異常”かつDが最頻度ではない→最頻度に置換
# # それ以外→そのまま

# freqD <- function(vect) {
#   tmp_table <- table(vect)
#   tmp_table_D <- tmp_table[names(tmp_table) == "D"]
#   if (length(tmp_table_D) == 0) {
#     tmp_table_D <- 0
#   }
#   return(as.integer(tmp_table_D))
# }

# freq <- unlist(apply(df_replacen, 2, freqD))
# freq <- log(freq)
# hotelling <- (freq - mean(freq))^2/var(freq)
# hotelling_cols <- which(hotelling > qchisq(0.95, 1))

# replaceD <- function (vect) {
#   tmp_table <- table(vect)
#   tmp_max <- which.max(tmp_table)
#   tmp_names <- names(tmp_max)[1]
#   if (tmp_names != "D") {
#     vect[vect == "D"] <- tmp_names
#   }
#   return(vect)
# }

# if (length(hotelling_cols) > 0) {
#   df_replacen[, hotelling_cols] <- apply(df_replacen[, hotelling_cols], 2, replaceD)
# }

write.table(df_replacen, "", sep = ",", quote = FALSE, row.names = TRUE, col.names = FALSE)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/03-preprocess/formatFasta.sh
#!/bin/sh

formatFasta() {
  cat "$1" |
    tr -d "\r" |
    paste - - |
    awk 'NF==2 {$2=toupper($2)}1'
}
EMBED
cat <<'EMBED' >.DAJIN_temp/library/03-preprocess/maskByPhred.sh
#!/bin/sh

fmtPhred() {
  cat - |
    grep -v "^@" |
    grep "cs:Z" |
    sort -k 1,1 -k 4,4n |
    cut -f 1,6,11 |
    awk '{gsub(",", "_", $NF)}1' |
    awk '
      function trimcrip(cigar, score) {
        match(cigar, /[0-9][0-9]*S/)
        leftclip=substr(cigar, RSTART, RLENGTH-1)
        sub(/[0-9][0-9]*S/, "", cigar)
        match(cigar, /[0-9][0-9]*S/)
        rightclip=substr(cigar, RSTART, RLENGTH-1)
        score=substr(score, leftclip+1)
        score=substr(score, 1, length(score)-rightclip)
        return score
      } {
      n_id[$1]++
      cigar=$2
      score=$3
      if(cigar~/S/) {
        score_of[$1] = score_of[$1] trimcrip(cigar, score)
      }
      else {
        score_of[$1] = score_of[$1] score
      }
    } END {
      for(id in score_of) {
        print id","score_of[id]
      }
    }' |
    sort -t,
}

maskMS() {
  awk -F, 'BEGIN {OFS=","} {
    readid=$1
    split($2, cigar, "")
    idx=1
    for (i=3; i<=NF; i++) {
      if ($i ~ /[0-9]/) {
        I=$i
        sub(/[MDSmds]$/, "", I)
        idx=idx+I+1
      }
      else if ($i == "D") {
        idx=idx
      }
      else if ($i ~ /[MS]/ && cigar[idx] ~ /[!"#$%&'\''()*]/) {
        $i="N"
        idx++
      }
      else {
        idx++
      }
    }
  }1' |
    cut -d, -f1,3-
}

maskByPhred() {
  maskByPhred="$(find .DAJIN_temp/ -name "maskByPhred.R")"
  cat "$1" |
    fmtPhred |
    join -t, - "$2" |
    maskMS |
    Rscript --vanilla "$maskByPhred"
}
EMBED
cat <<'EMBED' >.DAJIN_temp/library/03-preprocess/samToMIDS.sh
#!/bin/sh
# shellcheck disable=SC1091,SC2120

################################################################################
# input: SAM file using `minimap2 -ax splice --cs=long`
# output: Match(M), Insertion(1M), Deletion(D), Substitution(S), Inversion (mids) and "= (null)"
################################################################################

fmtSam() {
  cat - |
    awk '
    /^@SQ/ {
      for(i=1;i<=NF;i++) {
        if($i ~ /^SN:/) allele=$i
        if($i ~ /^LN:/) reflen=$i
      }
      sub(/.*SN:/,"", allele)
      sub(/.*LN:/,"", reflen)
    }
    /cs:Z:=/ {
      id=$1; flag=$2; start=$4
      for(i=1;i<=NF;i++) if ($i ~ /^cs:Z:=/) cstag=$i
      sub("cs:Z:=","",cstag)
      gsub("=", " ", cstag)
      gsub(/\+/, " ", cstag)
      gsub(/\-/, " -", cstag)
      gsub(/\*/, " *", cstag)
      gsub("~", " ~", cstag)
      $1=id","flag","start","allele","reflen
      $2=cstag
      print $1,$2
    }' |
    sort -t "," -k 3,3n
}

matchToM() {
  awk '{for(i=2;i<=NF;i++) gsub(/[ACGT]/, "M ", $i)}1'
}

subToS() {
  awk '{for(i=2;i<=NF;i++) gsub(/\*[acgt][acgt]/, "S ", $i)}1'
}

delToD() {
  awk '{
      for(i=2;i<=NF;i++) {
        if($i ~ /^-/) {
          str=""
          for(j=1;j<=int(length($i)-1);j++) str=str "D "
          $i=str
        }
      }}1'
}

insToNum() {
  awk '{
    for(i=3;i<=NF;i++) {
      if($i~/^[acgt]/){
        $i=length($i) $(i+1)
        $(i+1)=""
      }
    }}1'
}

padding() {
  awk '{
    start=$2-1
    end=$3
    len=NF-3+start
    pad_start=""
    pad_end=""
    for(i=1;i<=start;i++) pad_start=pad_start "D "
    $4=pad_start $4
    for(i=len;i<end;i++) pad_end=pad_end " D"
    $NF=$NF pad_end
  }1' |
    sed "s/  */ /g"
}

spaceTocomma() {
  sed -e "s/  */,/g" -e "s/,$//"
}

samToMIDS() (
  if [ -p /dev/stdin ] && [ "$#" -eq 0 ]; then
    cat -
  elif [ -r "$1" ]; then
    cat "$1"
  else
    echo "$*"
  fi |
    # cat test/samTomids/in/test_inv.sam |
    fmtSam |
    matchToM |
    subToS |
    delToD |
    awk '{$1=$1","}1' |
    #* Large deletion and Inversion -------------------------
    awk -F, '
      function padD(iter,    i,str) {
        for (i=1; i<=iter; i++) str=str " D "
        return str
      }

      function ins_rm(string) {
        gsub("[acgt][acgt]*", "", string)
        return string
      }

      function csCat(c_of, s_of, iter,    i,cs) {
        for(i=1; i<=iter; i++) {
          _cs=c_of[i]
          ins_rm(_cs)
          gap_length=s_of[i+1] - s_of[i] - gsub(/[MIDSmids]/, "", _cs)
          cs=cs c_of[i] padD(gap_length)
        }
        cs=cs c_of[iter+1]
        return cs
      }

    {
      num_of_alignment[$1]++
      start_of[$1]=start_of[$1]","$3
      allele=$4
      reflen=$5
      cstag_of[$1]=cstag_of[$1]","$6
    } END {
      for (read_id in num_of_alignment) {
        sub(/^,/, "" ,start_of[read_id])
        sub(/^,/, "" ,cstag_of[read_id])
        split(start_of[read_id], s_of, ",")
        split(cstag_of[read_id], c_of, ",")
        #* normal
        if (num_of_alignment[read_id]==1) {
          cs=c_of[1]
        }
        #* large deletion
        else if (num_of_alignment[read_id]==2) {
          if (allele !~ /(control)|(wt)/) {
            c_of[1] = padD(gsub(/[MIDS]/, "", c_of[1]))
            c_of[2] = padD(gsub(/[MIDS]/, "", c_of[2]))
          }
          cs=csCat(c_of, s_of, 1)
          }
        #* inversion
        else if (num_of_alignment[read_id]==3) {
          c_of[2] = tolower(c_of[2])
          cs=csCat(c_of, s_of, 2)
        }
      print read_id, s_of[1], reflen, cs
    }}' |
    insToNum |
    padding |
    spaceTocomma |
    awk -F, 'NF==$3+3' |
    cut -d, -f 1,4- |
    grep -v "^$" |
    sort -t,
)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/03-preprocess/maskFastq.sh
#!/bin/sh

maskFastq() {
  if [ -p /dev/stdin ] && [ _"$*" = _"" ]; then
    cat -
  elif [ -r "$*" ]; then
    cat "$*"
  else
    echo "$*"
  fi |
    sed "s/^@/\n@/" |
    awk 'BEGIN{RS=""; FS="\n"; OFS="\n"} {
    split($2, sequence, "")
    n=split($NF, quality, "")
    for(i=1 && seq=""; i<=n; i++) {
      if (quality[i] ~ "[!\"#$%&'\''()*]") {
        seq=seq "N"
      }
      else {
        seq=seq sequence[i]
      }
    }
    $2=seq
  }1'
}
EMBED
cat <<'EMBED' >.DAJIN_temp/library/03-preprocess/maskByPhred.py
import pandas as pd

df = pd.read_csv("tmp_maskMS.csv", header=None)

tmp = df[3]
EMBED
cat <<'EMBED' >.DAJIN_temp/library/04-phasing/rowColSums.R
#!/usr/bin/env Rscript

args <- commandArgs(trailingOnly = TRUE)

df_row <- read.table(args[1], sep = ",", header = FALSE, row.names = 1)
df_col <- read.table(args[2], sep = ",", header = FALSE, row.names = 1)

df <- df_row + df_col

write.table(df,
  file = "",
  sep = ",", col.names = FALSE, row.names = TRUE, quote = FALSE
)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/04-phasing/colScore.R
#!/usr/bin/env Rscript

args <- commandArgs(trailingOnly = TRUE)
if (length(args) > 0) {
  df <- read.table(args[1], sep = ",", header = FALSE, row.names = 1)
} else {
  df <- read.table(".DAJIN_temp/tmp_expansion_barcode25_control.csv", sep = ",", header = FALSE, row.names = 1)
}

list_table <- apply(df, 2, table)

for (idx in seq(length(list_table))) {
  values <- names(list_table[[idx]])
  values <- as.integer(values)
  for (val in values[values > 0]) {
    df[[idx]][df[[idx]] == val] <-
      list_table[[idx]][values == val]
  }
}

write.table(df,
  file = "",
  sep = ",", col.names = FALSE, row.names = TRUE, quote = FALSE
)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/04-phasing/svLof.py
import sys
import pandas as pd
from sklearn.neighbors import LocalOutlierFactor
import argparse

################################################################################
# Input
################################################################################

parser = argparse.ArgumentParser()
parser.add_argument("-c", "--control", default=".DAJIN_temp/classif/tmp_control")
parser.add_argument("-s", "--sample", default=".DAJIN_temp/classif/tmp_control")
parser.add_argument("-t", "--threads", default="1")
args = parser.parse_args()

df_control = pd.read_csv(args.control, header=None)
df_sample = pd.read_csv(args.sample, header=None)
threads = int(args.threads)

################################################################################
# LOF
################################################################################

lof = LocalOutlierFactor(
    n_neighbors=20,
    algorithm="auto",
    leaf_size=30,
    metric="euclidean",
    contamination="auto",
    novelty=True,
    n_jobs=threads,
)

lof.fit(df_control)

output = pd.Series(lof.predict(df_sample))

################################################################################
# Output
################################################################################

output.to_csv(sys.stdout, index=False, header=False)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/04-phasing/clustering.R
################################################################################
# Install required packages
################################################################################

if (!requireNamespace("dbscan", quietly = TRUE)) {
  install.packages("dbscan", repos = "https://cloud.r-project.org/")
}

################################################################################
# Input
################################################################################

args <- commandArgs(trailingOnly = TRUE)
if (length(args) > 0) {
  df_score <- read.csv(args[1], header = FALSE, stringsAsFactors = FALSE)
  pca_hotelling <- read.csv(args[2], header = FALSE)
  threads <- as.integer(args[3])
} else {
  df_score <- read.csv(
    ".DAJIN_temp/clustering/tmp_score.csv",
    header = FALSE, stringsAsFactors = FALSE
  )
  threads <- as.integer(parallel::detectCores() - 1)
}

df_score <- df_score[, colSums(df_score) != 0]

################################################################################
# PCA as a preprocessing step
################################################################################

pca <- prcomp(df_score, scale = FALSE)

pc_num <- 1:5
pc_score <- as.data.frame(pca$x[, pc_num])
prop_var <- pca$sdev[pc_num]^2 / sum(pca$sdev[pc_num]^2)
pc_score <- sweep(pc_score, 2, prop_var, FUN = "*")

###? DEBUG
# library("tidyverse")
# df_pca <- tibble(PC1 = pca$x[, 1], PC2 = pca$x[, 2])
# ggplot(df_pca, aes(x = PC1, y = PC2)) +
#   geom_point()

# ggplot(pc_score, aes(x = seq_along(.data$PC1), y = PC1)) +
#   geom_point()

# sum(pc_score$PC1 > 0)
# sum(pc_score$PC1 < 0)

# ggplot(as_tibble(t(df_score[1:2, ])), aes(x = seq_along(.data$"1"), y = .data$"1")) +
#   geom_point()
# ggplot(as_tibble(t(df_score[1:2, ])), aes(x = seq_along(.data$"1"), y = .data$"2")) +
#   geom_point()

# # tmp <- abs(df_score[1, ] - df_score[2, ])
# # which.max(tmp)
# df_score[2, 6051] %>% head()

####### DEBUG

################################################################################
# Clustering
################################################################################

# ===========================================================
# Extract cluster size with the largest cluster size
# and the most frequent cluster numbers
# ===========================================================

cl_seq <-
  as.integer(seq(nrow(pc_score) * 0.2, nrow(pc_score) * 0.4, length.out = 10)) + 2

hdb <- parallel::mclapply(cl_seq,
  function(.x) length(unique(dbscan::hdbscan(pc_score, minPts = .x)$cluster)),
  mc.cores = threads
)
hdb <- unlist(setNames(hdb, cl_seq))
hdb <- hdb[hdb != 1]

if (length(hdb) > 0) {
  cl_mode <- names(which.max(table(hdb)))
  cl_size <- as.integer(max(names(hdb[hdb == cl_mode])))
} else {
  cl_size <- max(cl_seq)
}

cl_hdb <- dbscan::hdbscan(pc_score, minPts = cl_size)$cluster + 1

# ===========================================================
# Repeat clustering
# ===========================================================

for (.cl in unique(cl_hdb)) {
  .df_score <- df_score[cl_hdb == .cl, ]
  .pca <- prcomp(.df_score, scale = FALSE)
  if (length(pc_num) > ncol(.pca$x)) next
  .pc_score <- as.data.frame(.pca$x[, pc_num])
  .prop_var <- .pca$sdev[pc_num]^2 / sum(.pca$sdev[pc_num]^2)
  .pc_score <- sweep(.pc_score, 2, .prop_var, FUN = "*")
  .minPts <- as.integer(nrow(.pc_score) * 0.4) + 2L
  .cl_hdb <- dbscan::hdbscan(.pc_score, minPts = .minPts)$cluster + 1L
  cl_hdb[cl_hdb == .cl] <- .cl_hdb + (.cl * 100)
}
cl_hdb <- as.integer(as.factor(cl_hdb))

################################################################################
# Output
################################################################################

write(cl_hdb, stdout(), ncolumns = 1)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/04-phasing/scoreToScalar.sh
#!/bin/sh

scoreToScalar() {
  if [ -p /dev/stdin ] && [ "$#" -eq 0 ]; then
    cat -
  elif [ -r "$1" ]; then
    cat "$1"
  else
    echo "$*"
  fi |
    awk -F, 'BEGIN {OFS=","} {
    sum=0
    for(i=2; i<=NF; i++) sum+=$i
    print $1, log(sum/(NF-1))
  }'
}
EMBED
cat <<'EMBED' >.DAJIN_temp/library/04-phasing/rowColMul.R
#!/usr/bin/env Rscript

args <- commandArgs(trailingOnly = TRUE)

df_row <- read.table(args[1], sep = ",", header = FALSE, row.names = 1)
df_col <- read.table(args[2], sep = ",", header = FALSE, row.names = 1)

df <- df_row * df_col

write.table(df,
  file = "",
  sep = ",", col.names = FALSE, row.names = TRUE, quote = FALSE
)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/04-phasing/filterMinorCluster.sh
#!/bin/sh

filterMinorCluster() {
  timestamp "Filter minor alleles" log_DAJIN.txt

  cat - |
    tee .DAJIN_temp/clustering/tmp_"$sample_name" |
    cut -d, -f1-2 |
    sort |
    uniq -c |
    awk '{
      sum+=$1
      num[NR]=$1
      allele[NR]=$2
      } END {
      for(i=1; i<=NR; i++)
        print allele[i],num[i],num[i]/sum*100
    }' |
    awk '$3>1 {print $1}' |
    tr "," "_" |
    sort >.DAJIN_temp/clustering/tmp_allele

  cat .DAJIN_temp/clustering/tmp_"$sample_name" |
    sed "s/,/_/" |
    sort |
    join -t, - .DAJIN_temp/clustering/tmp_allele |
    sed "s/_/,/"

  rm .DAJIN_temp/clustering/tmp_*
}
EMBED
cat <<'EMBED' >.DAJIN_temp/library/04-phasing/midsToScore.sh
#!/bin/sh
# shellcheck disable=SC1091,SC2120

################################################################################
# input: MIDS (id, MIDS)
# output: MIDS score (id, I, D, S)
################################################################################

expansion() {
  if [ -p /dev/stdin ] && [ "$#" -eq 0 ]; then
    cat -
  elif [ -r "$1" ]; then
    cat "$1"
  else
    echo "$*"
  fi |
    awk -F, '
    function mids_score(I,D,S) {
      $(i+(LEN)*0)=I
      $(i+(LEN)*1)=D
      $(i+(LEN)*2)=S
    }
    function invToD(data) {
      id=$1
      gsub(/[mids]/, "D", $0)
      $1=id
    }
    BEGIN {OFS=","} {
    LEN=NF-1
    invToD($0)
    for(i=2;i<=NF;i++) {
      if($i=="M")
        mids_score(0,0,0)
      #* insertion->match
      else if ($i~/[0-9]+M/) {
        sub("M$","",$i)
        $i = $i * $i
        mids_score($i,0,0)
        }
      #* insertion->deletion
      else if ($i~/[0-9]+D/) {
        sub("D$","",$i)
        $i = $i * $i
        mids_score($i,1,0)
      }
      #* insertion->substitution
      else if ($i~/[0-9]+S/) {
        sub("S$","",$i)
        $i = $i * $i
        mids_score($i,0,1)
      }
      else if($i=="D") {
        mids_score(0,1,0)
      }
      else if($i=="S") {
        mids_score(0,0,1)
      }
    }
  }1'
}

mutToat() {
  awk '
    BEGIN {
      FS=","
      OFS=""
    } {
    $1=$1","
    ins_nf=(NF-1)/3
    for (i=2; i<=ins_nf; i++) {
      $i=$i","
    }
    for (i=ins_nf+1; i<=NF; i++) {
      if ($i>0 && $(i+1)>0)
        $i="@"
      else if ($(i-1)=="@" && $i==1)
        $i="@,"
      else
        $i=$i","
    }
    sub(",$", "", $NF)
  }1'
}

atToscore() {
  awk '
    BEGIN {
      FS=","
      OFS=","
    } {
    for (i=2; i<=NF; i++) {
      n=""
      if ($i ~ /@/) {
        num=length($i)
        for (j=1; j<=num; j++) n=n num ","
        sub(",$", "", n)
        $i=n
      }
    }
  }1'
}

rowScore() {
  cat "$1" |
    mutToat |
    atToscore
}

colScore() {
  colScore="$(find .DAJIN_temp/ -name "colScore.R")"
  Rscript --vanilla "$colScore" "$1"
}

# rowColSums() {
#   rowColSums="$(find .DAJIN_temp/ -name "rowColSums.R")"
#   Rscript --vanilla "$rowColSums" "$1" "$2"
# }

rowColMul() {
  rowColMul="$(find .DAJIN_temp/ -name "rowColMul.R")"
  Rscript --vanilla "$rowColMul" "$1" "$2"
}

midsToScore() {
  mkdir -p .DAJIN_temp
  suffix="${1##*/}"
  expansion "$1" >.DAJIN_temp/tmp_expansion_"$suffix"
  rowScore .DAJIN_temp/tmp_expansion_"$suffix" >.DAJIN_temp/tmp_row_"$suffix"
  colScore .DAJIN_temp/tmp_expansion_"$suffix" >.DAJIN_temp/tmp_col_"$suffix"
  rowColMul .DAJIN_temp/tmp_row_"$suffix" .DAJIN_temp/tmp_col_"$suffix"
  rm .DAJIN_temp/tmp_*"$suffix"
}
EMBED
cat <<'EMBED' >.DAJIN_temp/library/04-phasing/calcHotelling.sh
#!/bin/sh

calcHotelling() (
  if [ -p /dev/stdin ] && [ _"$*" = _"" ]; then
    cat -
  elif [ -r "$*" ]; then
    cat "$*"
  else
    echo "$*"
  fi |
    awk '{
      data[NR]=$0
      sum+=$1
    } END {
      mean=sum/NR
      for(i=1;i<=NR;i++) {
        residual+=(data[i]-mean)^2
      }
      var=residual/NR
      for(i=1;i<=NR;i++) {
        hotelling=(data[i]-mean)^2/var
        print hotelling
      }
    }'
)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/04-phasing/clustering.py
import sys
import os
import numpy as np
import pandas as pd
import hdbscan
import joblib
from sklearn.decomposition import PCA

################################################################################
# Input
################################################################################

args = sys.argv
if args != [""]:
    df_score = pd.read_csv(args[1], header=None)
    threads = int(args[2])
else:
    df_score = pd.read_csv(".DAJIN_temp/clustering/tmp_score.csv", header=None)
    threads = os.cpu_count() - 1

tmp = (df_score.sum(axis=0) != 0).to_list()
df_score = df_score.loc[:, tmp]

################################################################################
# PCA as a preprocessing step
################################################################################

pca = PCA(n_components=5)
pc_score = pca.fit_transform(df_score)
prop_var = pca.explained_variance_ratio_
pc_score = pd.DataFrame(pc_score) * prop_var

################################################################################
# Clustering
################################################################################

# ===========================================================
# Extract cluster size with the largest cluster size
# and the most frequent cluster numbers
# ===========================================================


def hdb_cl_num(cl_size):
    cl = hdbscan.HDBSCAN(
        min_samples=1,
        min_cluster_size=cl_size,
        core_dist_n_jobs=threads,
        memory=joblib.Memory(location=".DAJIN_temp/clustering", verbose=0),
    )
    tmp = cl.fit_predict(pc_score)
    return len(np.unique(tmp))


def hdb_predict(data, cl_size):
    cl = hdbscan.HDBSCAN(
        min_samples=1,
        min_cluster_size=cl_size,
        core_dist_n_jobs=threads,
        memory=joblib.Memory(location=".DAJIN_temp/clustering", verbose=0),
    )
    return cl.fit_predict(data) + 1


cl_range = [int(n) for n in np.linspace(
    len(pc_score) * 0.2, len(pc_score) * 0.4, 10) + 2]

hdb = [hdb_cl_num(cl_num) for cl_num in cl_range]
# hdb = [i for i in hdb if i != 1]

if len(hdb) > 0:
    _uniqs, _counts = np.unique(hdb, return_counts=True)
    max_mode = max(_uniqs[_counts == np.amax(_counts)])
    cl_index = max([i for i, x in enumerate(hdb) if x == max_mode])
    cl_size = cl_range[cl_index]
else:
    cl_size = max(cl_range)


cl_hdb = hdb_predict(pc_score, cl_size) + 2

# ===========================================================
# Repeat clustering
# ===========================================================

for _cl in np.unique(cl_hdb):
    if sum(cl_hdb == _cl) <= 5:
        continue
    _df_score = df_score[cl_hdb == _cl]
    _pca = PCA(n_components=5)
    _pc_score = _pca.fit_transform(_df_score)
    _prop_var = _pca.explained_variance_ratio_
    _pc_score = pd.DataFrame(_pc_score) * _prop_var
    _cl_size = int(len(_pc_score) * 0.4 + 2)
    _cl_hdb = hdb_predict(_pc_score, _cl_size) + 2
    cl_hdb[cl_hdb == _cl] = _cl_hdb + (_cl * 100)

cl_hdb = pd.Series(cl_hdb).rank(method="dense").astype(int)

################################################################################
# Output
################################################################################

cl_hdb.to_csv(sys.stdout, index=False, header=False)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/06-consensus/calcFreqMIDS.sh
#!/bin/sh

################################################################################
# Input: CSV including allele, MIDS (e.g: normal_control,M,M,M,M,M,M,M)
# Output: CSV including allele, loc, M freq, I freq, D freq, and S freq (e.g: normal_control,998,0.888889,0,0.111111,0)
################################################################################

calcFreqMIDS() (
  # Input from pipe or file or or stdin
  if [ -p /dev/stdin ] && [ _"$*" = _"" ]; then
    cat -
  elif [ -r "$*" ]; then
    cat "$*"
  else
    echo "$*"
  fi |
    awk -F, 'BEGIN {OFS=","} {
    num_of[$1]++
    nf_of[$1]=NF
    for(i=2;i<=NF;i++) {
      mids[$1,i,$i]++
      }
    } END {
    for(type in num_of) {
      for(i=2;i<=nf_of[type];i++) {
        (mids[type, i, "M"]) ? M=mids[type, i, "M"]/num_of[type] : M=0
        (mids[type, i, "I"]) ? I=mids[type, i, "I"]/num_of[type] : I=0
        (mids[type, i, "D"]) ? D=mids[type, i, "D"]/num_of[type] : D=0
        (mids[type, i, "S"]) ? S=mids[type, i, "S"]/num_of[type] : S=0
        print type,i-1,M,I,D,S
      }
    }
  }'
)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/06-consensus/margeCStoMIDS.R
#!/usr/bin/env Rscript

###############################################################################
# Input files
###############################################################################

args <- commandArgs(trailingOnly = TRUE)
if (length(args) > 0) {
  df_cs <- read.table(args[1], sep = ",", header = FALSE, row.names = 1)
  df_mids <- read.table(args[2], sep = ",", header = FALSE, row.names = 1)
} else {
  df_cs <- read.table("tmp_cs", sep = ",", header = FALSE, row.names = 1)
  df_mids <- read.table("tmp_mids", sep = ",", header = FALSE, row.names = 1)
}
colnames(df_cs) <- seq(ncol(df_cs))
df_fa <- read.table(".DAJIN_temp/fasta/control.fa", skip = 1, header = FALSE)
c_fa <- strsplit(df_fa$V1, "")[[1]]

###############################################################################
# Extract mutation
###############################################################################

locIDS <- which(df_mids != "M")
df_mutIDS <- df_mids[locIDS, ]
df_csIDS <- df_cs[locIDS]

l_csmut <-
  lapply(seq_along(df_mutIDS), function(x) {
  mut <- df_mutIDS[[x]]
  cs <- df_csIDS[[x]]
  csmut <- cs[grepl(mut, cs)]
  return(csmut)
})
names(l_csmut) <- seq_along(df_mutIDS)
l_table <- lapply(l_csmut, table)
l_max <- (lapply(l_table, which.max))
l_names <- lapply(l_max, names)

v_mut <- unlist(l_names)
v_mut <- sub("[IS]", "", v_mut)

###############################################################################
# Embed mutation to FASTA
###############################################################################

c_fa[locIDS] <- v_mut

###############################################################################
# Output embedded FASTA
###############################################################################

write.table(
  cbind(df_mids, c_fa),
  file = "",
  sep = ",",
  col.names = FALSE,
  row.names = TRUE,
  quote = FALSE
)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/06-consensus/csToCSV.sh
#!/bin/sh
# shellcheck disable=SC1091,SC2120

################################################################################
# input: SAM file using `minimap2 -ax splice --cs=long`
# output: DNA sequence with MIDS separation (location, MIDS, Nucreotide)
################################################################################

fmtSam() {
  cat - |
    awk '
    /^@SQ/ {
      for(i=1;i<=NF;i++) {
        if($i ~ /^SN:/) allele=$i
        if($i ~ /^LN:/) reflen=$i
      }
      sub(/.*SN:/,"", allele)
      sub(/.*LN:/,"", reflen)
    }
    /cs:Z:=/ {
      id=$1; flag=$2; start=$4
      for(i=1;i<=NF;i++) if ($i ~ /^cs:Z:=/) cstag=$i
      sub("cs:Z:=","",cstag)
      gsub("=", " ", cstag)
      gsub(/\+/, " +", cstag)
      gsub(/\-/, " -", cstag)
      gsub(/\*/, " *", cstag)
      gsub("~", " ~", cstag)
      $1=id","flag","start","allele","reflen
      $2=cstag
      print $1,$2
    }' |
    sort -t "," -k 1,1 -k 3,3n
}

matchToSpace() {
  awk '{
    for(i=2;i<=NF;i++)
      gsub(/[ACGT]/, "& ", $i)
  }1'
}

subToNuc() {
  awk '{
    for (i=2;i<=NF;i++) {
      if ($i ~ /^\*/) {
        gsub(/\*[acgt]/, "S", $i)
      }
  }}1'
}

delToD() {
  awk '{
    for(i=2;i<=NF;i++) {
      if($i ~ /^-/) {
        str=""
        for(j=1; j<=int(length($i)-1); j++) str=str " D "
        $i=str
      }
    }}1'
}

largeDelAndInvToNuc() {
  awk -F, '
      function padD(iter,    i,str) {
        for (i=1; i<=iter; i++) str=str " D "
        return str
      }

      function ins_rm(string) {
        gsub("[acgt][acgt]*", "", string)
        return string
      }

      function csCat(c_of, s_of, iter,    i,cs) {
        for(i=1; i<=iter; i++) {
          _cs=c_of[i]
          ins_rm(_cs)
          gap_length=s_of[i+1] - s_of[i] - gsub(/[ACGTacgt]/, "", _cs)
          cs=cs c_of[i] padD(gap_length)
        }
        cs=cs c_of[iter+1]
        return cs
      }

    {
      num_of_alignment[$1]++
      start_of[$1]=start_of[$1]","$3
      allele=$4
      reflen=$5
      cstag_of[$1]=cstag_of[$1]","$6
    } END {
      for (read_id in num_of_alignment) {
        sub(/^,/, "" ,start_of[read_id])
        sub(/^,/, "" ,cstag_of[read_id])
        split(start_of[read_id], s_of, ",")
        split(cstag_of[read_id], c_of, ",")
        #* normal
        if (num_of_alignment[read_id]==1) {
          cs=c_of[1]
        }
        #* large deletion
        else if (num_of_alignment[read_id]==2) {
          cs=csCat(c_of, s_of, 1)
          }
        #* inversion
        else if (num_of_alignment[read_id]==3) {
          c_of[2] = tolower(c_of[2])
          cs=csCat(c_of, s_of, 2)
        }
      print read_id, s_of[1], reflen, cs
    }}'
}

insToNuc() {
  awk '{
    for (i=4; i<=NF; i++) {
      if ($i ~ /^\+/){
        sub(/\+/, "", $i)
        if ($(i+1) ~ /^[SD]/) {
          $i = "I" $i $(i+1)
          $(i+1) = ""
        }
        else {
          $i = "I" $i substr($(i+1), 1, 1)
          sub(/[ACGT]/, "", $(i+1))
        }
      }
    }}1'
}

padding() {
  awk '{
    start=$2-1
    end=$3
    len=NF-3+start
    pad_start=""
    pad_end=""
    for (i=1;i<=start;i++)
      pad_start = pad_start " = "
    for (i=len;i<end;i++)
      pad_end = pad_end " = "
    $4 = pad_start $4
    $NF = $NF pad_end
  }1' |
    sed "s/  */ /g"
}

spaceTocomma() {
  sed -e "s/  */,/g" -e "s/,$//"
}

csToCSV() (
  if [ -p /dev/stdin ] && [ "$#" -eq 0 ]; then
    cat -
  elif [ -r "$1" ]; then
    cat "$1"
  else
    echo "$*"
  fi |
    # cat test/csToCSV/que.sam |
    fmtSam |
    matchToSpace |
    subToNuc |
    delToD |
    awk '{$1=$1","}1' |
    largeDelAndInvToNuc |
    insToNuc |
    padding |
    spaceTocomma |
    awk -F, 'NF==$3+3' |
    cut -d, -f 1,4- |
    grep -v "^$" |
    sort -t,
)
EMBED
cat <<'EMBED' >.DAJIN_temp/library/general.sh
#!/bin/sh

error_exit() {
  echo "ERROR: $1" >&2
  echo "ERROR: $1" >>log_DAJIN.txt
  [ "${TEST:-}" ] || rm -rf .DAJIN_temp/ 2>/dev/null
  exit 1
}

###? DEBUG
# terminate() {
#   trap '' TERM
#   kill -TERM 0
#   [ "${TEST:-}" ] || rm -rf .DAJIN_temp/ 2>/dev/null
#   exit "$1"
# }
# trap "terminate 130" INT
# trap "terminate 143" TERM

timestamp() {
  echo "$(date +'%Y-%m-%d %H:%M:%S') | $1" >>"${2:-log_DAJIN.txt}"
  echo "$(date +'%Y-%m-%d %H:%M:%S') | $1" >&2
}

load_control() {
  find "$1" -type f |
    while read -r line; do
      output=${line#/tmp/.DAJIN_temp/}
      output=${output%.gz}
      gzip -dc "$line" >.DAJIN_temp/"$output"
    done
}

save_control() {
  find "$1" -type f |
    grep "$control_name" |
    while read -r line; do
      output=${line#\.DAJIN_temp/}.gz
      gzip -c "$line" >/tmp/.DAJIN_temp/"$output"
    done
}

open() {
  if file "$1" | grep -q gzip; then
    gzip -dc "$1"
  else
    cat "$1"
  fi
}
EMBED
. .DAJIN_temp/library/03-preprocess/formatFasta.sh
. .DAJIN_temp/library/03-preprocess/maskByPhred.sh
. .DAJIN_temp/library/03-preprocess/samToMIDS.sh
. .DAJIN_temp/library/03-preprocess/maskFastq.sh
. .DAJIN_temp/library/general.sh
. .DAJIN_temp/library/06-consensus/calcFreqMIDS.sh
. .DAJIN_temp/library/06-consensus/csToCSV.sh
. .DAJIN_temp/library/04-phasing/scoreToScalar.sh
. .DAJIN_temp/library/04-phasing/filterMinorCluster.sh
. .DAJIN_temp/library/04-phasing/midsToScore.sh
. .DAJIN_temp/library/04-phasing/calcHotelling.sh
ARGS="$*" && export ARGS
cat <<'EMBED' >.DAJIN_temp/script/01-init/01-init.sh
#!/bin/sh

set -eu
umask 0022
export LC_ALL=C

[ "${BASH_VERSION:-}" ] && set -o posix -o pipefail
[ "${ZSH_VERSION:-}" ] && setopt shwordsplit interactivecomments

: >log_DAJIN.txt
timestamp "Start analysis" log_DAJIN.txt
echo "DAJIN $*" >>log_DAJIN.txt
EMBED
cat <<'EMBED' >.DAJIN_temp/script/02-args/01-parse.sh
#!/bin/sh

[ "$#" -eq 0 ] && grep -v '```' .DAJIN_temp/document/usage.md && exit 0

while [ "$#" -gt 0 ]; do
  case "$1" in
  -h | --help)
    grep -v '```' .DAJIN_temp/document/usage.md
    exit 0
    ;;
  -v | --version)
    grep -v '```' .DAJIN_temp/document/version.md
    exit 0
    ;;

  #--- parse arguments
  -a | --alleles)
    alleles="$2"
    shift
    ;;
  -c | --control)
    control="$2"
    shift
    ;;
  -s | --sample)
    sample="$2"
    shift
    ;;
  -g | --genome)
    genome="$2"
    shift
    ;;
  -o | --output)
    output_dir="$2"
    shift
    ;;
  -t | --threads)
    threads="$2"
    shift
    ;;

  #--- error handling
  -*) echo "Unrecognized option: $1" && exit 1 ;;
  *) echo "Unrecognized argument: $1" && exit 1 ;;
  esac
  shift
done

################################################################################
# Check arguments
################################################################################

# Check mandatory arguments ------------

echo "$ARGS" |
  grep -q -e "\-a " -e "\--alleles " ||
  error_exit "-a|--alleles argument is required"

[ -r "$alleles" ] || error_exit "$alleles is not found"

grep -q -e '>wt' -e ">control" "$alleles" ||
  error_exit "$alleles must include '>control' or '>wt'"

echo "$ARGS" |
  grep -q -e "\-c " -e "\--control " ||
  error_exit "-c|--control argument is required"

[ -r "$control" ] || error_exit "$control is not found"

echo "$ARGS" |
  grep -q -e "\-s " -e "\--sample " ||
  error_exit "-s|--sample argument is required"

[ -r "$sample" ] || error_exit "$sample is not found"

control_name="$(basename "$control" | sed "s/\..*$//" | tr " " "_")"
sample_name="$(basename "$sample" | sed "s/\..*$//" | tr " " "_")"

[ "${control_name:-}" ] || error_exit "$control is an invalid file name."
[ "${sample_name:-}" ] || error_exit "$sample is an invalid file name"

# Check optional arguments ------------
EMBED
cat <<'EMBED' >.DAJIN_temp/script/02-args/02-depend.sh
#!/bin/sh

################################################################################
# Chech dependencies
################################################################################

# curl or wget ------------------------------------------------

if type wget >/dev/null 2>&1; then
  CMD_CHECK='wget -q -O - --spider --tries=2 --wait=1 --timeout=5'
  CMD_GET='wget -q -O -'
elif type curl >/dev/null 2>&1; then
  CMD_CHECK='curl --retry 2 --retry-delay 1 -s -o /dev/null -w "%{http_code}"'
  CMD_GET='curl -s'
else
  error_exit 'No HTTP-GET/POST command found.'
fi

# Commands ------------------------------------------------

cat <<EOF |
  minimap2
  samtools
  gzip
  python
EOF
  while read -r CMD; do
    "$CMD" --version >/dev/null 2>&1 || error_exit "$CMD: command not found"
  done

# R packages ----------------------------------------------
# Rscript --slave --vanilla .DAJIN_temp/library/install_pkgs.R 1>/dev/null 2>&1

# Rscript --slave --vanilla -e "installed.packages()" >.DAJIN_temp/rpackages

# cat <<EOF |
#   dbscan
#   ggplot2
#   RColorBrewer
# EOF
#   while read -r RPKG; do
#     grep -q "$RPKG" .DAJIN_temp/rpackages || error_exit "$RPKG: package not found in R"
#   done

# rm .DAJIN_temp/rpackages

# Python packages ----------------------------------------

pip freeze >.DAJIN_temp/pypackages

cat <<EOF |
  numpy
  pandas
  scikit-learn
  hdbscan
  joblib
  plotnine
EOF
  while read -r PYPKG; do
    grep -q "$PYPKG" .DAJIN_temp/pypackages || error_exit "$PYPKG: package not found in Python"
  done

rm .DAJIN_temp/pypackages
EMBED
cat <<'EMBED' >.DAJIN_temp/script/03-preprocess/010-fasta.sh
#!/bin/sh

mkdir -p .DAJIN_temp/fasta/

formatFasta "${alleles}" |
  while read -r line; do
    output="$(echo ${line#>} | cut -d " " -f 1)"
    [ _"$output" = "_wt" ] && output="control"
    echo "$line" |
      tr " " "\n" >.DAJIN_temp/fasta/"$output".fa
  done
EMBED
cat <<'EMBED' >.DAJIN_temp/script/03-preprocess/015-fastq.sh
#!/bin/sh

mkdir -p .DAJIN_temp/fastq /tmp/.DAJIN_temp/fastq

# if find /tmp/fastq/"$control_name"* 1>/dev/null 2>&1; then
#   gzip -dc /tmp/fastq/"$control_name".fq.gz >.DAJIN_temp/fastq/"$control_name".fq
#   open "$sample" | maskFastq >.DAJIN_temp/fastq/"$sample_name".fq
# else
#   {
#     open "$control" | maskFastq >.DAJIN_temp/fastq/"$control_name".fq &
#     open "$sample" | maskFastq >.DAJIN_temp/fastq/"$sample_name".fq &
#     wait
#   } 1>/dev/null 2>&1
#   gzip -c .DAJIN_temp/fastq/"$control_name".fq >/tmp/fastq/"$control_name".fq.gz
# fi

open "$control" >.DAJIN_temp/fastq/"$control_name".fq
open "$sample" >.DAJIN_temp/fastq/"$sample_name".fq
EMBED
cat <<'EMBED' >.DAJIN_temp/script/03-preprocess/020-sam.sh
#!/bin/sh

#----------------------------------------------------------
timestamp "Generate SAM files" >>log_DAJIN.txt
#----------------------------------------------------------

outdir=.DAJIN_temp/sam/
mkdir -p "$outdir" /tmp/"$outdir"/

find .DAJIN_temp/fasta/*.fa |
  while read -r fasta; do
    allele_name="$(basename ${fasta%.fa})"

    if find /tmp/"$outdir"/"$control_name"_"$allele_name".bam 1>/dev/null 2>&1; then
      samtools view /tmp/"$outdir"/"$control_name"_"$allele_name".bam \
        >"$outdir"/"$control_name"_"$allele_name".sam
    else
      minimap2 -t "$threads" --cs=long \
        -ax map-ont "$fasta" .DAJIN_temp/fastq/"$control_name".fq 2>/dev/null \
        >"$outdir"/"$control_name"_"$allele_name".sam
      samtools sort -@ "$threads" "$outdir"/"$control_name"_"$allele_name".sam \
        >/tmp/"$outdir"/"$control_name"_"$allele_name".bam 2>/dev/null
    fi

    minimap2 -t "$threads" --cs=long \
      -ax map-ont "$fasta" .DAJIN_temp/fastq/"$sample_name".fq 2>/dev/null \
      >"$outdir"/"$sample_name"_"$allele_name".sam
  done
EMBED
cat <<'EMBED' >.DAJIN_temp/script/03-preprocess/030-mids.sh
#!/bin/sh

#----------------------------------------------------------
timestamp "MIDS encoding" >>log_DAJIN.txt
#----------------------------------------------------------

mkdir -p .DAJIN_temp/mids /tmp/.DAJIN_temp/mids

multi_samToMIDS() {
  cmd=". $(find .DAJIN_temp/ -name samToMIDS.sh); samToMIDS"
  find .DAJIN_temp/sam/"${1:-}"*.sam |
    while read -r line; do
      output="${line%.*}".csv
      output="$(echo $output | sed "s|/sam/|/mids/|")"
      echo "$line" |
        sed "s|^|$cmd |" |
        sed "s|$| >$output \&|"
    done |
    awk -v th="${threads:-1}" '
    {if (NR%(th+1) == 0) print "wait"}
    END {print "wait"}1' |
    sh
}

if find /tmp/.DAJIN_temp/mids/"$control_name"* 1>/dev/null 2>&1; then
  multi_samToMIDS "$sample_name"
  load_control /tmp/.DAJIN_temp/mids
else
  multi_samToMIDS
  save_control .DAJIN_temp/mids
fi
EMBED
cat <<'EMBED' >.DAJIN_temp/script/03-preprocess/035-mids-filter.sh
#!/bin/sh

mkdir -p .DAJIN_temp/midsfilter/

find .DAJIN_temp/mids/*.csv |
  while read -r line; do
    cat "$line" |
      awk -F, '{
      leftD=0
      rightD=0
      for (i=2; i<=51; i++) {
        if ($i=="D") leftD++
      }
      for (i=NF-49; i<=NF; i++) {
        if ($i=="D") rightD++
      }
      if ( leftD!=50 && rightD!=50)
        print $0
      }' >.DAJIN_temp/midsfilter/"$(basename "$line")"
  done
EMBED
cat <<'EMBED' >.DAJIN_temp/script/03-preprocess/040-mids-mask.sh
#!/bin/sh

mkdir -p .DAJIN_temp/midsmask /tmp/.DAJIN_temp/midsmask

multi_maskByPhred() {
  cmd=". $(find .DAJIN_temp/ -name maskByPhred.sh); maskByPhred"
  find .DAJIN_temp/sam/"${1:-}"*.sam -print0 |
    xargs -0 -I@ basename @ |
    sed "s/.sam$//" |
    while read -r line; do
      sam=.DAJIN_temp/sam/"$line".sam
      mids=.DAJIN_temp/midsfilter/"$line".csv
      output="$(echo $mids | sed "s|/midsfilter/|/midsmask/|")"
      echo "$sam" "$mids" |
        sed "s|^|$cmd |" |
        sed "s|$| >$output \&|"
    done |
    awk -v th="${threads:-1}" '
    {if (NR%(th+1) == 0) print "wait"}
    END {print "wait"}1' |
    sh
}

if find /tmp/.DAJIN_temp/midsmask/"$control_name"* 1>/dev/null 2>&1; then
  multi_maskByPhred "$sample_name"
  load_control /tmp/.DAJIN_temp/midsmask/
else
  multi_maskByPhred
  save_control .DAJIN_temp/midsmask/
fi
EMBED
cat <<'EMBED' >.DAJIN_temp/script/03-preprocess/050-mids-subtract.sh
#!/bin/sh
EMBED
cat <<'EMBED' >.DAJIN_temp/script/04-phasing/002-score.sh
#!/bin/sh

cat <<EOF >>log_DAJIN.txt
==========================================================
Classify alleles...
==========================================================
EOF

#----------------------------------------------------------
timestamp "MIDS scoring" log_DAJIN.txt
#----------------------------------------------------------

mkdir -p .DAJIN_temp/score /tmp/.DAJIN_temp/score

multi_midsToScore() {
  cmd=". $(find .DAJIN_temp/ -name midsToScore.sh); midsToScore"
  find .DAJIN_temp/midsmask/"${1:-}"*.csv |
    while read -r line; do
      output="${line%.*}".csv
      output="$(echo $output | sed "s|/midsmask/|/score/|")"
      echo "$line" |
        sed "s|^|$cmd |" |
        sed "s|$| >$output \&|"
    done |
    awk -v th="${threads:-1}" '
    {if (NR%(th+1) == 0) print "wait"}
    END {print "wait"}1' |
    sh
}

if find /tmp/.DAJIN_temp/score/"$control_name"* 1>/dev/null 2>&1; then
  multi_midsToScore "$sample_name"
  load_control /tmp/.DAJIN_temp/score
else
  multi_midsToScore
  save_control .DAJIN_temp/score
fi
EMBED
cat <<'EMBED' >.DAJIN_temp/script/04-phasing/003-scalar.sh
#!/bin/sh

mkdir -p .DAJIN_temp/scalar /tmp/.DAJIN_temp/scalar

multiscoreToScalar() {
  cmd=". $(find .DAJIN_temp/ -name scoreToScalar.sh); scoreToScalar"
  find .DAJIN_temp/score/"${1:-}"* |
    grep -e "$sample_name" -e "$control_name"_wt -e "$control_name"_control |
    while read -r line; do
      output="$(echo $line | sed "s|/score/|/scalar/|")"
      echo "$line" |
        sed "s|^|$cmd |" |
        sed "s|$| >$output \&|"
    done |
    awk -v th="${threads:-1}" '
    {if (NR%(th+1) == 0) print "wait"}
    END {print "wait"}1' |
    sh
}

if find /tmp/.DAJIN_temp/scalar/"$control_name"* 1>/dev/null 2>&1; then
  multiscoreToScalar "$sample_name"
  load_control /tmp/.DAJIN_temp/scalar
else
  multiscoreToScalar
  save_control .DAJIN_temp/scalar
fi
EMBED
cat <<'EMBED' >.DAJIN_temp/script/04-phasing/025-classif.sh
#!/bin/sh

#----------------------------------------------------------
timestamp "Allele classification" log_DAJIN.txt
#----------------------------------------------------------

mkdir -p .DAJIN_temp/classif

find .DAJIN_temp/scalar/"$sample_name"* |
  while read -r line; do
    allele=$(basename "${line%.csv}" | cut -d_ -f2-)
    awk -v al="$allele" '{print al","$0}' "$line"
  done |
  awk -F, '{
    allele=$1
    read=$2
    score=$3
    if(score_of[read] == "") score_of[read]="inf"
    if(score_of[read]>score) {
      output[read]=$0
      score_of[read]=score
    }} END {
      for(read in output) print output[read]
    }' |
  cat >.DAJIN_temp/classif/"$sample_name".csv
EMBED
cat <<'EMBED' >.DAJIN_temp/script/04-phasing/030-svcall.sh
#!/bin/sh

#----------------------------------------------------------
timestamp "SV allele detetction" log_DAJIN.txt
#----------------------------------------------------------

mkdir -p .DAJIN_temp/sv/
control_scalar=$(find .DAJIN_temp/scalar/"$control_name"*)

# control =================================================
# LOFだと値が小さすぎる（きれいにマッピングされすぎる）リードもSVと判定されてしまうため,
# 中央値よりも値が小さいリードはすべて正常と判定させる.
median_score=$(
  cat $control_scalar |
    awk -F, '$NF ~ /e-/ {$NF=0}1' |
    sort -t, -n -k2,2 |
    awk -F, -v wc="$(wc -l <$control_scalar)" 'NR==int(wc/2) {print $NF}'
)

cat "$control_scalar" |
  cut -d, -f2 |
  calcHotelling |
  paste -d, "$control_scalar" - |
  awk -F, -v median="$median_score" '!($2 > median && $NF > 3.841459) {print $2}' | #qchisq(0.95,1)
  cat >.DAJIN_temp/sv/tmp_control_score

# sample =================================================

cat .DAJIN_temp/classif/"$sample_name".csv |
  tee .DAJIN_temp/sv/tmp_sample |
  cut -d, -f3 |
  cat >.DAJIN_temp/sv/tmp_sample_score

# SV detection  =================================================
svLof="$(find .DAJIN_temp -name "svLof.py")"
python "$svLof" \
  -c .DAJIN_temp/sv/tmp_control_score \
  -s .DAJIN_temp/sv/tmp_sample_score \
  -t "$threads" |
  awk '{($1 == 1) ? $1="normal" : $1="SV"}1' |
  paste -d, - .DAJIN_temp/sv/tmp_sample .DAJIN_temp/sv/tmp_sample_score |
  awk -F, -v median="$median_score" '{
    if($1=="SV" && $NF<median) $1="normal"
    if($1=="SV") $2="SV"
    print $2","$3
   }' |
  cat >.DAJIN_temp/sv/"$sample_name".csv

rm .DAJIN_temp/sv/tmp*

#? DEBUG ===
# head .DAJIN_temp/sv/"$sample_name".csv
# cat .DAJIN_temp/sv/"$sample_name".csv | cut -d, -f1 | sort | uniq -c
# cat .DAJIN_temp/sam/"$sample_name"_target.sam | grep 3284ac08-c086-4cbc-b871-8ddab98f42a0 | grep "[acgt]"
# cat .DAJIN_temp/sam/"$sample_name"_wt.sam | grep 3284ac08-c086-4cbc-b871-8ddab98f42a0 | grep "[acgt]"

# cat .DAJIN_temp/scalar/"$sample_name"_target.csv | grep 3284ac08-c086-4cbc-b871-8ddab98f42a0
# cat .DAJIN_temp/scalar/"$sample_name"_wt.csv | grep 3284ac08-c086-4cbc-b871-8ddab98f42a0
EMBED
cat <<'EMBED' >.DAJIN_temp/script/04-phasing/040-clustering.sh
#!/bin/sh

#----------------------------------------------------------
timestamp "Clustering" log_DAJIN.txt
#----------------------------------------------------------

mkdir -p .DAJIN_temp/clustering/

cat .DAJIN_temp/sv/"$sample_name".csv |
  cut -d, -f 1 |
  sort |
  uniq -c |
  while read -r num classif; do
    allele="$classif"
    [ _"$classif" = "_SV" ] && allele=control
    #
    grep "^$classif" .DAJIN_temp/sv/"$sample_name".csv |
      cut -d, -f2 |
      sort -u |
      join -t, .DAJIN_temp/score/"$sample_name"_"$allele".csv - |
      cat >.DAJIN_temp/clustering/tmp_sample.csv
    #
    cat .DAJIN_temp/clustering/tmp_sample.csv |
      cut -d, -f1 >.DAJIN_temp/clustering/tmp_id.csv

    if [ "$num" -gt 5 ]; then
      cat .DAJIN_temp/clustering/tmp_sample.csv |
        cut -d, -f2- >.DAJIN_temp/clustering/tmp_score.csv
      clustering="$(find .DAJIN_temp/ -name "clustering.py")"
      python "$clustering" .DAJIN_temp/clustering/tmp_score.csv "$threads"
    else
      awk -v num="$num" 'BEGIN{for(i=1;i<=num;i++) print 1}'
    fi |
      paste -d, - .DAJIN_temp/clustering/tmp_id.csv |
      sed "s/^/${classif},/"
  done |
  if [ _"${filter:-on}" = _"on" ]; then
    filterMinorCluster
  fi |
  #* format allele numbers
  awk -F, 'BEGIN {OFS=","; clust_num=1} {
    allele=$1
    clust=$2
    id=$1","$2
    if(a_allele[allele]=="") {
      a_allele[allele]++
      clust_num=1
    }
    if(a_id[id]=="") {
      a_id[id]++
      allele_num[id]=clust_num
      clust_num++
      }
    $2=allele_num[id]
  }1' |
  sort -u >.DAJIN_temp/clustering/"$sample_name".csv

rm .DAJIN_temp/clustering/tmp* 2>/dev/null || :
rm -rf .DAJIN_temp/clustering/joblib/ 2>/dev/null || :

# ###? DEBUG
# cat .DAJIN_temp/clustering/"$sample_name".csv |
#   cut -d, -f 1-2 |
#   sort |
#   uniq -c
EMBED
cat <<'EMBED' >.DAJIN_temp/script/05-bam/010-bam.sh
#!/bin/sh

#----------------------------------------------------------
timestamp "Generate BAM files" log_DAJIN.txt
#----------------------------------------------------------

mkdir -p .DAJIN_temp/bam/ /tmp/.DAJIN_temp/bam/

# Control
if find /tmp/.DAJIN_temp/bam/"$control_name".bam >/dev/null 2>&1; then
  cp /tmp/.DAJIN_temp/bam/"$control_name".bam* .DAJIN_temp/bam/
else
  cat .DAJIN_temp/sam/"$control_name"*_control.sam |
    samtools sort -@ "$threads" >.DAJIN_temp/bam/"$control_name".bam 2>/dev/null
  samtools index -@ "$threads" .DAJIN_temp/bam/"$control_name".bam
  cp .DAJIN_temp/bam/"$control_name".bam /tmp/.DAJIN_temp/bam/
fi

# Sample
cat .DAJIN_temp/sam/"$sample_name"*_control.sam |
  samtools sort -@ "$threads" >.DAJIN_temp/bam/"$sample_name".bam 2>/dev/null
samtools index -@ "$threads" .DAJIN_temp/bam/"$sample_name".bam

cat .DAJIN_temp/clustering/"$sample_name".csv |
  cut -d, -f 1,2 |
  sort -u |
  while read -r line; do
    classif="${line%%,*}"
    number="${line##*,}"
    suffix="$classif"_"$number"

    grep "^$line" .DAJIN_temp/clustering/"$sample_name".csv |
      cut -d, -f3 |
      sort -u >.DAJIN_temp/bam/tmp_id

    grep "^@" .DAJIN_temp/sam/"$sample_name"*_control.sam >.DAJIN_temp/bam/tmp_header

    grep -v "^@" .DAJIN_temp/sam/"$sample_name"*_control.sam |
      sort |
      join - .DAJIN_temp/bam/tmp_id |
      tr " " "\t" |
      cat .DAJIN_temp/bam/tmp_header - |
      samtools sort -@ "$threads" >.DAJIN_temp/bam/"$sample_name"_"$suffix".bam 2>/dev/null
    samtools index -@ "$threads" .DAJIN_temp/bam/"$sample_name"_"$suffix".bam
  done

rm .DAJIN_temp/bam/tmp_*
EMBED
cat <<'EMBED' >.DAJIN_temp/script/06-consensus/010-freqMIDS.sh
#!/bin/sh

. "$(find .DAJIN_temp -name calcFreqMIDS.sh)"

outdir=.DAJIN_temp/consensus/freqmids/
mkdir -p "$outdir" /tmp/"$outdir"

#? MEMO =========================
#? calcFreqMIDSの１列目のID指定はいらないみたい
#?  =========================

# control =================================================

if [ -r /tmp/"$outdir"/"$control_name".csv.gz ]; then
  cp /tmp/"$outdir"/"$control_name".csv.gz "$outdir"
  gzip -f -d "$outdir"/"$control_name".csv.gz
else
  cat .DAJIN_temp/midsmask/"$control_name"_control.csv |
    cut -d, -f 2- |
    sed "s/^/control,/" |
    sed "s/,[0-9][0-9]*M/,IM/g" |
    sed "s/,[0-9][0-9]*D/,ID/g" |
    sed "s/,[0-9][0-9]*S/,IS/g" |
    calcFreqMIDS |
    sed "s/,/@/" |
    sort -u -t, |
    cat >"$outdir"/"$control_name".csv
  cp "$outdir"/"$control_name".csv /tmp/"$outdir"/
  gzip /tmp/"$outdir"/"$control_name".csv
fi

# sample  =================================================

cat .DAJIN_temp/clustering/"$sample_name".csv |
  cut -d, -f1-2 |
  sort -u |
  while read -r line; do
    suffix="$(echo "$line" | tr , _)"
    grep "^$line" .DAJIN_temp/clustering/"$sample_name".csv |
      cut -d, -f3 |
      sort -u >"$outdir"/tmp_"$suffix"

    cat .DAJIN_temp/midsmask/"$sample_name"*_control.csv |
      join -t, - "$outdir"/tmp_"$suffix" |
      cut -d, -f 2- |
      sed "s/^/control,/" |
      sed "s/,[0-9][0-9]*M/,IM/g" |
      sed "s/,[0-9][0-9]*D/,ID/g" |
      sed "s/,[0-9][0-9]*S/,IS/g" |
      calcFreqMIDS |
      sed "s/,/@/" |
      sort -u -t, |
      cat >"$outdir"/"$sample_name"_"$suffix".csv
  done

rm "$outdir"/tmp_*
EMBED
cat <<'EMBED' >.DAJIN_temp/script/06-consensus/020-consMIDS.sh
#!/bin/sh

outdir=.DAJIN_temp/consensus/consmids/
mkdir -p "$outdir" /tmp/"$outdir"

#? MEMO =========================
#?  =========================

find .DAJIN_temp/consensus/freqmids/"$sample_name"* |
  while read -r line; do
    outfile="$(basename "$line")"
    cat "$line" |
      join -t, - .DAJIN_temp/consensus/freqmids/"$control_name".csv |
      awk -F, 'function RELU(v) {return v < 0 ? 0 : v}
        BEGIN {OFS=","} {
        subI=RELU($3-$7)
        subD=RELU($4-$8)
        subS=RELU($5-$9)
        subM=RELU(1-subI-subD-subS)
        # print subM,subI,subD,subS
        if ($3>0.9) MIDS="I"
        else if ($4>0.9) MIDS="D"
        else if ($5>0.9) MIDS="S"
        #* sequence error
        else if (subI>subM && subI>subD && subI>subS) MIDS="I"
        else if (subD>subM && subD>subI && subD>subS) MIDS="D"
        else if (subS>subM && subS>subI && subS>subD) MIDS="S"
        else MIDS="M"
        print $0,MIDS
      }' |
      tr "@" "," |
      awk -F, '{print $2","$NF}' |
      sort -t, -n |
      grep ^ >"$outdir"/"$outfile"
  done
EMBED
cat <<'EMBED' >.DAJIN_temp/script/06-consensus/030-fmtCStag.sh
#!/bin/sh

outdir=.DAJIN_temp/consensus/fmtcs/
mkdir -p "$outdir" /tmp/"$outdir"

grep "^@" .DAJIN_temp/sam/"$sample_name"_control.sam >"$outdir"/tmp_header
sort .DAJIN_temp/sam/"$sample_name"_control.sam >"$outdir"/tmp_sam

cat .DAJIN_temp/clustering/"$sample_name".csv |
  cut -d, -f1-2 |
  sort -u |
  while read -r line; do
    suffix="$(echo $line | tr , _)"
    grep "^$line" .DAJIN_temp/clustering/"$sample_name".csv |
      cut -d, -f 3 |
      sort |
      join - "$outdir"/tmp_sam |
      tr " " "\t" |
      cat "$outdir"/tmp_header - >"$outdir"/"$sample_name"_"$suffix".sam
  done

multi_csToCSV() {
  cmd=". $(find .DAJIN_temp/ -name csToCSV.sh); csToCSV"
  find "$outdir"/*.sam |
    while read -r line; do
      output="${line%.*}".csv
      echo "$line" |
        sed "s|^|$cmd |" |
        sed "s|$| >$output \&|"
    done |
    awk -v th="${threads:-1}" '
    {if (NR%(th+1) == 0) print "wait"}
    END {print "wait"}1' |
    sh
}

multi_csToCSV

rm .DAJIN_temp/consensus/fmtcs/*sam
rm .DAJIN_temp/consensus/fmtcs/tmp*

# #? DEBUG =========================================

# cut -d, -f1-2 .DAJIN_temp/clustering/"$sample_name".csv | sort | uniq -c
# wc -l "$outdir"/*
# cat .DAJIN_temp/consensus/fmtcs/barcode31_SV_1.csv | cut -d, -f1 | sort >tmp_id
# grep "^@" .DAJIN_temp/sam/"$sample_name"_control.sam >tmp_header
# sort .DAJIN_temp/sam/"$sample_name"_control.sam |
#   join -v 2 tmp_id - |
#   tr " " "\t" |
#   cat tmp_header - |
#   head >tmp.sam

# # ハードクリップがあるリードの扱いはどうする？
# # 001179a7-d376-42d5-9671-dde7bff87c93

# sort .DAJIN_temp/sam/"$sample_name"_control.sam | awk '$6 ~ /H/' | head

# cat tmp.sam |
#   fmtSam |
#   matchToSpace |
#   subToNuc |
#   delToD |
#   awk '{$1=$1","}1' |
#   largeDelAndInvToNuc |
#   insToNuc |
#   padding |
#   spaceTocomma |
#   awk -F, 'NF==$3+3' |
#   cut -d, -f 1,4- |
#   grep -v "^$" |
#   sort -t,

# cat tmp.sam |
#   fmtSam |
#   matchToSpace |
#   subToNuc |
#   delToD |
#   awk '{$1=$1","}1' |
#   largeDelAndInvToNuc |
#   cat >tmp
# cat tmp | grep "G +t Sa St St A"

# echo "id 1 2845 G +t Sa St St A" |
#   insToNuc |
#   padding |
#   spaceTocomma
EMBED
cat <<'EMBED' >.DAJIN_temp/script/06-consensus/040-mergeCStoMIDS.sh
#!/bin/sh

outdir=.DAJIN_temp/consensus/merge/
mkdir -p "$outdir"

find .DAJIN_temp/consensus/fmtcs/*.csv |
  while read -r line; do
    consMIDS=.DAJIN_temp/consensus/consmids/"$(basename "$line")"
    if grep -q "[IDS]" "$consMIDS"; then
      Rscript --vanilla "$(find .DAJIN_temp -name margeCStoMIDS.R)" \
        "$line" "$consMIDS" |
        cat >"$outdir"/"$(basename "$line")"
    fi
  done

#? DEBUG ============================================
# cat "$line" >tmp_cs
# cat "$consMIDS" >tmp_mids
EMBED
cat <<'EMBED' >.DAJIN_temp/script/06-consensus/050-consensus.sh
#!/bin/sh

echo "consensus" #?????????????????
exit 0           #?????????????????

mkdir -p .DAJIN_temp/consensus /tmp/.DAJIN_temp/consensus
control_scalar=.DAJIN_temp/scalar/"$control_name"_control.csv

# control =================================================

cat .DAJIN_temp/midsmask/barcode32_control.csv |

  # LOFだと値が小さすぎる（きれいにマッピングされすぎる）リードもSVと判定されてしまうため,
  # 中央値よりも値が小さいリードはすべて正常と判定させる.
  median_score=$(
    cat $control_scalar |
      awk -F, '$NF ~ /e-/ {$NF=0}1' |
      sort -t, -n -k2,2 |
      awk -F, -v wc="$(wc -l <$control_scalar)" 'NR==int(wc/2) {print $NF}'
  )

cat "$control_scalar" |
  cut -d, -f2 |
  calcHotelling |
  paste -d, "$control_scalar" - |
  awk -F, -v median="$median_score" '!($2 > median && $NF > 3.841459) {print $1}' | #qchisq(0.95,1)
  sort -u |
  join -t, .DAJIN_temp/score/"$control_name"_control.csv - |
  cat >.DAJIN_temp/consensus/tmp_control_score
EMBED
. .DAJIN_temp/script/01-init/01-init.sh
. .DAJIN_temp/script/02-args/01-parse.sh
. .DAJIN_temp/script/02-args/02-depend.sh
. .DAJIN_temp/script/03-preprocess/010-fasta.sh
. .DAJIN_temp/script/03-preprocess/015-fastq.sh
. .DAJIN_temp/script/03-preprocess/020-sam.sh
. .DAJIN_temp/script/03-preprocess/030-mids.sh
. .DAJIN_temp/script/03-preprocess/035-mids-filter.sh
. .DAJIN_temp/script/03-preprocess/040-mids-mask.sh
. .DAJIN_temp/script/03-preprocess/050-mids-subtract.sh
. .DAJIN_temp/script/04-phasing/002-score.sh
. .DAJIN_temp/script/04-phasing/003-scalar.sh
. .DAJIN_temp/script/04-phasing/025-classif.sh
. .DAJIN_temp/script/04-phasing/030-svcall.sh
. .DAJIN_temp/script/04-phasing/040-clustering.sh
. .DAJIN_temp/script/05-bam/010-bam.sh
. .DAJIN_temp/script/06-consensus/010-freqMIDS.sh
. .DAJIN_temp/script/06-consensus/020-consMIDS.sh
. .DAJIN_temp/script/06-consensus/030-fmtCStag.sh
. .DAJIN_temp/script/06-consensus/040-mergeCStoMIDS.sh
. .DAJIN_temp/script/06-consensus/050-consensus.sh
