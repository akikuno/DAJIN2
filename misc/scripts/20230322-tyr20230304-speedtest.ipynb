{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 今回の取り組み"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- preprocessで時間がかかりすぎているので、速度が遅い部分を調べる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## いつものセットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/DAJIN_R10/DAJIN2\n"
     ]
    }
   ],
   "source": [
    "# ルートディレクトリをPathに含めるおまじない\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "if Path(os.getcwd()).stem != \"DAJIN2\":\n",
    "    parent_path = str(Path(os.path.dirname(os.path.abspath(\"__file__\"))).parent.parent)\n",
    "    sys.path.append(parent_path)\n",
    "    os.chdir(parent_path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# pipの更新\n",
    "pip install -q -U pip\n",
    "pip install -q -U -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `preprocess.correct_sequence_error`と`preprocess.correct_knockin`でシークエンスエラーではない変異箇所を抽出する\n",
    "- もしくは、コードを独立させたほうが良いかもしれません\n",
    "    - correctionが終わったあとに、sampleとcontrolと比べて変異のある塩基位置を抽出する\n",
    "    - correctionと独立させることで、correctionの方法が変わっても塩基位置を抽出するコードを変える必要がなくなる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test-20230304-pm-tyr...\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "from src.DAJIN2.core import preprocess, classification, clustering, consensus, report\n",
    "from src.DAJIN2.core.clustering import clustering\n",
    "\n",
    "reload(preprocess)\n",
    "reload(classification)\n",
    "reload(clustering)\n",
    "reload(consensus)\n",
    "reload(report)\n",
    "\n",
    "\n",
    "# ##### # * R9 vs R10 Point mutation\n",
    "SAMPLE, CONTROL, ALLELE, NAME, GENOME, DEBUG, THREADS = (\n",
    "    \"../fastq_20230304/barcode31.fq.gz\",\n",
    "    \"../fastq_20230304/barcode32.fq.gz\",\n",
    "    \"examples/pm-tyr/design_tyr.fa\",\n",
    "    \"test-20230304-pm-tyr\",\n",
    "    \"mm10\",\n",
    "    True,\n",
    "    6,\n",
    ")\n",
    "\n",
    "print(f\"processing {NAME}...\")\n",
    "\n",
    "##########################################################\n",
    "# Check inputs\n",
    "##########################################################\n",
    "preprocess.check_inputs.check_files(SAMPLE, CONTROL, ALLELE)\n",
    "TEMPDIR = Path(\"DAJINResults\", \".tempdir\", NAME)\n",
    "IS_CACHE_CONTROL = preprocess.check_inputs.exists_cached_control(CONTROL, TEMPDIR)\n",
    "IS_CACHE_GENOME = preprocess.check_inputs.exists_cached_genome(GENOME, TEMPDIR, IS_CACHE_CONTROL)\n",
    "UCSC_URL, GOLDENPATH_URL = None, None\n",
    "if GENOME and not IS_CACHE_GENOME:\n",
    "    UCSC_URL, GOLDENPATH_URL = preprocess.check_inputs.check_and_fetch_genome(GENOME)\n",
    "\n",
    "##########################################################\n",
    "# Format inputs\n",
    "##########################################################\n",
    "SAMPLE_NAME = preprocess.format_inputs.extract_basename(SAMPLE)\n",
    "CONTROL_NAME = preprocess.format_inputs.extract_basename(CONTROL)\n",
    "FASTA_ALLELES = preprocess.format_inputs.dictionize_allele(ALLELE)\n",
    "THREADS = min(THREADS, os.cpu_count()-1)\n",
    "\n",
    "preprocess.format_inputs.make_directories(TEMPDIR, SAMPLE_NAME, CONTROL_NAME)\n",
    "\n",
    "if GENOME:\n",
    "    GENOME_COODINATES = preprocess.format_inputs.fetch_coodinate(GENOME, UCSC_URL, FASTA_ALLELES[\"control\"])\n",
    "    CHROME_SIZE = preprocess.format_inputs.fetch_chrom_size(GENOME_COODINATES[\"chr\"], GENOME, GOLDENPATH_URL)\n",
    "    preprocess.format_inputs.cache_coodinates_and_chromsize(TEMPDIR, GENOME, GENOME_COODINATES, CHROME_SIZE)\n",
    "\n",
    "################################################################################\n",
    "# Export fasta files as single-FASTA format\n",
    "################################################################################\n",
    "# TODO: use yeild, not export\n",
    "for identifier, sequence in FASTA_ALLELES.items():\n",
    "    contents = \"\\n\".join([\">\" + identifier, sequence]) + \"\\n\"\n",
    "    output_fasta = Path(TEMPDIR, \"fasta\", f\"{identifier}.fasta\")\n",
    "    output_fasta.write_text(contents)\n",
    "###############################################################################\n",
    "# Mapping with mappy\n",
    "###############################################################################\n",
    "for path_fasta in Path(TEMPDIR, \"fasta\").glob(\"*.fasta\"):\n",
    "    name_fasta = path_fasta.stem\n",
    "    preprocess.mappy_align.output_sam(TEMPDIR, path_fasta, name_fasta, CONTROL, CONTROL_NAME, threads=THREADS)\n",
    "    preprocess.mappy_align.output_sam(TEMPDIR, path_fasta, name_fasta, SAMPLE, SAMPLE_NAME, threads=THREADS)\n",
    "    preprocess.mappy_align.output_sam(\n",
    "        TEMPDIR, path_fasta, name_fasta, CONTROL, CONTROL_NAME, preset=\"splice\", threads=THREADS\n",
    "    )\n",
    "    preprocess.mappy_align.output_sam(\n",
    "        TEMPDIR, path_fasta, name_fasta, SAMPLE, SAMPLE_NAME, preset=\"splice\", threads=THREADS\n",
    "    )\n",
    "########################################################################\n",
    "# MIDSV conversion\n",
    "########################################################################\n",
    "for path_sam in Path(TEMPDIR, \"sam\").glob(f\"{CONTROL_NAME}_splice_*\"):\n",
    "    preprocess.calc_midsv.output_midsv(TEMPDIR, path_sam)\n",
    "for path_sam in Path(TEMPDIR, \"sam\").glob(f\"{SAMPLE_NAME}_splice_*\"):\n",
    "    preprocess.calc_midsv.output_midsv(TEMPDIR, path_sam)\n",
    "###############################################################################\n",
    "# Correct CSSPLITS\n",
    "###############################################################################\n",
    "# preprocess.correct_revititive_deletions.execute(TEMPDIR, FASTA_ALLELES, CONTROL_NAME, SAMPLE_NAME)\n",
    "preprocess.correct_sequence_error.execute(TEMPDIR, FASTA_ALLELES, CONTROL_NAME, SAMPLE_NAME)\n",
    "preprocess.correct_knockin.execute(TEMPDIR, FASTA_ALLELES, CONTROL_NAME, SAMPLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import midsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele=\"control\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "midsv_control = midsv.read_jsonl((Path(TEMPDIR, \"midsv\", f\"{CONTROL_NAME}_splice_{allele}.jsonl\")))\n",
    "cssplits_control = [cs[\"CSSPLIT\"].split(\",\") for cs in midsv_control]\n",
    "# Sample\n",
    "midsv_sample = midsv.read_jsonl((Path(TEMPDIR, \"midsv\", f\"{SAMPLE_NAME}_splice_{allele}.jsonl\")))\n",
    "cssplits_sample = [cs[\"CSSPLIT\"].split(\",\") for cs in midsv_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {2845: 48350})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "readnum = defaultdict(int)\n",
    "for cs in cssplits_control:\n",
    "    readnum[len(cs)] += 1\n",
    "\n",
    "print(readnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in midsv_control:\n",
    "    cs = m[\"CSSPLIT\"].split(\",\")\n",
    "    if len(cs) != 2845:\n",
    "        print(m[\"QNAME\"], len(cs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAJINResults/.tempdir/test-20230304-pm-tyr/midsv/barcode32_splice_control.jsonl\n"
     ]
    }
   ],
   "source": [
    "print(Path(TEMPDIR, \"midsv\", f\"{CONTROL_NAME}_splice_{allele}.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat \"DAJINResults/.tempdir/test-20230304-pm-tyr/sam/barcode32_map-ont_control.sam\" |\n",
    "    grep -e \"^@\" -e \"9d00aba6d0fe\" |\n",
    "    cat > tmp_9d00aba6d0fe.sam\n",
    "\n",
    "cat \"DAJINResults/.tempdir/test-20230304-pm-tyr/sam/barcode32_map-ont_control.sam\" |\n",
    "    grep -e \"^@\" -e \"278e14de22da\" |\n",
    "    cat > tmp_278e14de22da.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat \"DAJINResults/.tempdir/test-20230304-pm-tyr/sam/barcode32_map-ont_control.sam\" |\n",
    "    grep -e \"^@\" -e \"9d00aba6d0fe\" |\n",
    "    samtools sort > tmp_9d00aba6d0fe.bam\n",
    "    samtools index tmp_9d00aba6d0fe.bam\n",
    "\n",
    "cat \"DAJINResults/.tempdir/test-20230304-pm-tyr/sam/barcode32_map-ont_control.sam\" |\n",
    "    grep -e \"^@\" -e \"278e14de22da\" |\n",
    "    samtools sort > tmp_278e14de22da.bam\n",
    "    samtools index tmp_278e14de22da.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### midsvの更新(version 0.9.0 -> 0.9.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midsv                                     0.9.5      /mnt/f/midsv/src\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip list | grep midsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/DAJIN_R10/DAJIN2\n"
     ]
    }
   ],
   "source": [
    "# ルートディレクトリをPathに含めるおまじない\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "if Path(os.getcwd()).stem != \"DAJIN2\":\n",
    "    parent_path = str(Path(os.path.dirname(os.path.abspath(\"__file__\"))).parent.parent)\n",
    "    sys.path.append(parent_path)\n",
    "    os.chdir(parent_path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import midsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele=\"control\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "midsv_control = midsv.read_jsonl((Path(TEMPDIR, \"midsv\", f\"{CONTROL_NAME}_splice_{allele}.jsonl\")))\n",
    "cssplits_control = [cs[\"CSSPLIT\"].split(\",\") for cs in midsv_control]\n",
    "# Sample\n",
    "midsv_sample = midsv.read_jsonl((Path(TEMPDIR, \"midsv\", f\"{SAMPLE_NAME}_splice_{allele}.jsonl\")))\n",
    "cssplits_sample = [cs[\"CSSPLIT\"].split(\",\") for cs in midsv_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {2845: 48350})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "readnum = defaultdict(int)\n",
    "for cs in cssplits_control:\n",
    "    readnum[len(cs)] += 1\n",
    "\n",
    "print(readnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in midsv_control:\n",
    "    cs = m[\"CSSPLIT\"].split(\",\")\n",
    "    if len(cs) != 2845:\n",
    "        print(m[\"QNAME\"], len(cs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MIDSVの更新をして、最終的にリファレンス配列と長さが異なる配列を除去することにしました"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 次に取り組むこと"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists\n",
    "\n",
    "+ [ ] cis変異の両端が欠失している場合に、Nで置き換えるとtransとなってしまうのをどうするか（`replace_n`）\n",
    "+ [ ] 短いリードの扱いをどうするべきか\n",
    "+ [ ] Insertionのなかにある変異を同定する手法を考案する\n",
    "+ [ ] Ayabe-taks1のright_loxpがいまいちな理由を考察する\n",
    "+ [ ] `preprocess.correct_sequence_error.replace_atmark`のコードがわかりにくい\n",
    "    + テストを用意してリファクタリングする"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focus\n",
    "+ [ ] cis変異の両端が欠失している場合に、Nで置き換えるとtransとなってしまうのをどうするか（`replace_n`）\n",
    "+ [ ] 短いリードの扱いをどうするべきか\n",
    "\n",
    "両者については、`correct_sequence_error`などで補正するときに、**変異候補の塩基配列のみを対象とする**ことで対応できる可能性がある\n",
    "\n",
    "- 変異候補の塩基配列のみを対象とする\n",
    "    - 両端が欠失しているようなリードについて、変異候補部位を含まないリードは`uncategorized`といったカテゴリにできる\n",
    "    - よって**変異候補部位を含むか含まないか**を考えることで、短いリードや両端が欠失しているリードの分類が可能になる？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a09285d6cbc768c1977f96e8deb5ca1ec0d08675e9573ed6dfd37fd7d91de663"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
